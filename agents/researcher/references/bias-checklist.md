# Cognitive Bias Checklist

Research bias awareness, prevention protocols, and report bias detection.

---

## Study Design Biases

| Bias | Description | Check | Mitigation |
|------|-------------|-------|------------|
| **Confirmation bias** | Collecting only hypothesis-supporting data | Are questions neutral? | Include falsifiable questions |
| **Sampling bias** | Participants skewed to specific groups | Are recruitment channels diverse? | Recruit from multiple channels |
| **Self-selection bias** | Only enthusiastic users participate | Is incentive design appropriate? | Include passive users |
| **Professional participant bias** | Research-savvy participants | Checked participation history? | Screen out in screener |

---

## Interview Execution Biases

| Bias | Description | Sign | Mitigation |
|------|-------------|------|------------|
| **Social desirability bias** | Trying to give "good" answers | All-positive responses | Use behavior-based questions |
| **Leading bias** | Interviewer expectations influence responses | Participant watches interviewer's face | Start with open questions |
| **Primacy effect** | First impression dominates | First participant's opinion dominates | Randomize order |
| **Recency effect** | Overweighting latest information | Last participant's opinion dominates | Organize all data before analysis |
| **Hawthorne effect** | Behavior changes under observation | Unnatural behavior | Observe in natural environment |

---

## Analysis Biases

| Bias | Description | Check | Mitigation |
|------|-------------|-------|------------|
| **Cherry-picking** | Selecting only convenient data | What data was excluded? | Systematically code all data |
| **Pattern recognition bias** | Finding non-existent patterns | Statistically significant? | Multi-person review |
| **Hindsight bias** | Believing results were predictable | Too aligned with prior hypothesis? | Document hypotheses beforehand |
| **Anchoring** | Fixating on initial information | Updated initial hypothesis? | Actively seek contradicting data |
| **Conformity bias** | Aligning with team opinion | Were dissenting views raised? | Individual analysis before sharing |

---

## Bias Prevention Protocol

### Study Design Checklist

**Question neutrality:**
- [ ] Using "What do you think about X?" not "Don't you think X is good?"
- [ ] Answer options have no positive/negative skew
- [ ] Avoiding yes/no binary; using scales instead
- [ ] Including behavior-specific questions

**Participant diversity:**
- [ ] Including different user segments
- [ ] Not only heavy users, but also light users
- [ ] Using multiple recruitment channels
- [ ] Checking geographic/demographic balance

**Procedure standardization:**
- [ ] Interview guide prepared
- [ ] Question order fixed (or intentionally randomized)
- [ ] Facilitator training conducted

### During Interview Checklist

**Opening:**
- [ ] Communicated "there are no right answers"
- [ ] Welcomed critical feedback
- [ ] Participant appears relaxed

**Questioning:**
- [ ] Started with open questions
- [ ] Used participant's words for follow-up probes
- [ ] Tolerated silence (didn't rush)
- [ ] Didn't express own opinion
- [ ] Didn't signal evaluation with reactions ("Great!")

**Recording:**
- [ ] Recorded participant's exact words
- [ ] Separated interpretation from fact
- [ ] Captured non-verbal reactions

### Analysis Checklist

**Data processing:**
- [ ] Reviewed all data before starting coding
- [ ] Created codebook in advance (or built inductively)
- [ ] Multiple coders independently coded then compared

**Interpretation:**
- [ ] Searched for contradicting data
- [ ] Asked "Why might this be wrong?"
- [ ] Considered alternative interpretations
- [ ] Acknowledged sample size limitations

**Reporting:**
- [ ] Documented methodology limitations
- [ ] Stated confidence levels ("Y of X participants")
- [ ] Reported counter-examples

---

## Bias Detection in Reports

### Dangerous Expressions

| Risky Phrasing | Bias Signal | Improved Phrasing |
|----------------|-------------|-------------------|
| "Everyone said..." | Sample size misunderstanding | "8 of 8 participants said..." |
| "Users prefer..." | Over-generalization | "Most study participants preferred..." |
| "Clearly..." | Confirmation bias | "Data suggests..." |
| "As expected..." | Hindsight bias | "Consistent with prior hypothesis..." |
| "Interestingly..." | Cherry-picking | State fact objectively |

### Review Questions

**Interpretation validity:**
- What data does NOT support this insight?
- What other interpretations could come from the same data?
- How far can we generalize from this sample?

**Reproducibility:**
- Would another researcher reach the same conclusion?
- Is methodology documented in sufficient detail?
- Is raw data accessible?

**Practicality:**
- Does this insight lead to action?
- Is the evidence sufficient for the recommendation?
- Have risks and uncertainties been communicated?
